{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "071257d8",
   "metadata": {},
   "source": [
    "# UT Austin CS 370 Undergraduate Research Project\n",
    "### Researcher: Tejas Saboo <br> Supervisor: Professor Angela Beasley\n",
    "\n",
    "Emerging technologies are disrupting the art industry and changing the way we create and experience art. As a computer science, mathematics, and statistics student with an appreciation for arts and culture, I decided to explore the intersection of art, design, and technology to identify and address opportunities to augment creativity through technology for my research project. The project entailed architecting a convolutional neural network model that classifies visual artwork by the artistic category and style.\n",
    "\n",
    "The final machine learning model presented is a deep convolutional neural network for the multi-class classification of the artistic style of visual artwork. The resulting model successfully classifies artwork with a 96% accuracy on the training set and a 69% accuracy on the validation set.\n",
    "\n",
    "I experimented with a variety of different technical approaches and model architectures throughout this project. First, I attempted to build a model that could distinguish between flower and marina paintings. Next, I discovered the Wikiart dataset and used the images for my model. Initially, I performed a manual train-test split by moving 80 images from each category into the training set and 20 images from each category into the test set. By limiting the size of the initial train and test sets, I was able to quickly train the models and continuously prototype the model architecture. Later, I learned how to use the shutil.move functionality to automate the process of moving a number of files from one directory to another, resulting in a scalable train-test split that also randomly shuffles the images. Regarding the model architecture, I experimented with various models, including linear and non-linear neural networks, fully convolutional neural networks, convolutional neural networks, and deep convolutional neural networks. After evaluating the different models, I found the deep convolutional neural network most effective in the classification of images of artwork.\n",
    "\n",
    "My future plans to build on this project include experimenting with computer vision to extract visual features and elements of the artwork such as line, shape, texture, form, space, color, value, composition, perspective, and subject matter to create algorithms that suggest tags for artwork. Next, I will create an algorithm that generates original and relevant titles for the artwork using the tags and extracted visual features. I will also investigate recent artificial intelligence and machine learning advancements to create an algorithm that measures the creativity and craftsmanship expemplified in the artwork and provides actionable feedback to help artists improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947860c",
   "metadata": {},
   "source": [
    "### Imports for ML Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238e7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98ff5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef19f4d",
   "metadata": {},
   "source": [
    "### Functions to Automate the Train-Test Dataset Split\n",
    "\n",
    "The move_shuffled_files function randomly selects num_files images from the src directory and moves them to the dest directory. \n",
    "\n",
    "The train_test_split function automates the process of moving files from the original wikiart directory to the train and test directories for every relevant artistic style category under consideration in an 80:20 split.\n",
    "\n",
    "Justification for 80:20 Split - https://scholarworks.utep.edu/cs_techrep/1209/\n",
    "TODO: Cite research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9845108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_shuffled_files(src, dest, num_files):\n",
    "    files = os.listdir(src)\n",
    "    for file_name in random.sample(files, num_files):\n",
    "        shutil.move(os.path.join(src, file_name), dest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdfd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    wiki_dirs = ['Pointillism', 'Realism']\n",
    "    base_src = 'wikiart/'\n",
    "    base_train_dest = 'data/train/'\n",
    "    base_test_dest = 'data/validation/'\n",
    "    for wiki_dir in wiki_dirs:\n",
    "        src = base_src + wiki_dir\n",
    "        train_dest = base_train_dest + wiki_dir\n",
    "        test_dest = base_test_dest + wiki_dir\n",
    "        move_shuffled_files(src, train_dest, 400)\n",
    "        move_shuffled_files(src, test_dest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b32866",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2144cf5c",
   "metadata": {},
   "source": [
    "### Train and Test Transform Functions To Set Up Images for the Model\n",
    "\n",
    "The train transform resizes the images to 256 x 256 (TODO: find older ipynb with research reference to why 256x256 or 64x64 is the ideal ratio in terms of performance versus time) and employes a variety of data augmentation techniques to reduce overfitting.\n",
    "\n",
    "TODO: Improve explanation of why each transform functionality was selected on how they all reduce overfitting. Explain that the test transform function does not employ these transformations because the test data should not be altered, but the resizing and totensor preprocessing is necessary for use in the model evaluation calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4e0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                      transforms.Resize([256, 256]),\n",
    "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      transforms.ColorJitter(0.5,0.5,0.5,0.5),\n",
    "                                      transforms.RandomGrayscale(0.05),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "                                      transforms.Resize([256, 256]),\n",
    "                                      transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba88238",
   "metadata": {},
   "source": [
    "### Generate Train and Test Sets\n",
    "\n",
    "The following 2 cells generate train and test sets for use in the model utilizing the above train and test transform functions. The datasets.ImageFolder method in torchvision's library facilitated the process of accessing images from desired folders while maintaining information about their class labels. \n",
    "\n",
    "TODO: Explain shuffling and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee11b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=\"data/train\", transform=train_transform)\n",
    "train = DataLoader(train_data, batch_size = 4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49d19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.ImageFolder(root=\"data/validation\", transform=test_transform)\n",
    "test = DataLoader(test_data, batch_size = 4, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d777ebc",
   "metadata": {},
   "source": [
    "### Deep Convolutional Neural Network\n",
    "\n",
    "TODO: Explain in more detail all of the model architectures that were designed and tested throughout this project, as well as all the variations to the DCNN model architecture that resulted in what is ultimately below. Explain methods used to avoid overfitting such as data augmentation in the train transform functions and adding dropout layers. Explain the benefits of the block structure and why it was used. Explain the various activation functions used. Summarize the overal design of the network in terms of how many blocks and how many layers, how each block is structured, and what modifications need to be made if the model is used for a multi-class classification problem for more classes than currently examined. Additionally, discuss the hyperparameter tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b370e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_kernel, conv_stride, conv_padding, pool_kernel, pool_stride):\n",
    "        super().__init__()\n",
    "        L = [\n",
    "            torch.nn.BatchNorm2d(in_channels),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels, out_channels, conv_kernel, conv_stride, conv_padding, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.nn.MaxPool2d(pool_kernel, pool_stride),\n",
    "        ]\n",
    "        self.network = torch.nn.Sequential(*L)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        in_channels = 3\n",
    "        out_channels = 32\n",
    "        num_classes = 2\n",
    "        kernel_size = 7\n",
    "        stride = 1\n",
    "        padding = 3\n",
    "        L = [\n",
    "            CNNBlock(in_channels, out_channels, kernel_size, stride, padding, 2, 2),\n",
    "            torch.nn.Dropout(p=0.2),\n",
    "            CNNBlock(32, 64, 3, 1, 1, 2, 2),\n",
    "            torch.nn.Dropout(p=0.25),\n",
    "            CNNBlock(64, 128, 3, 1, 1, 2, 2),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(32768, num_classes)\n",
    "        ]\n",
    "        self.network = torch.nn.Sequential(*L)\n",
    "        self.transforms = torchvision.transforms.Compose([torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transforms(x)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d336eda7",
   "metadata": {},
   "source": [
    "### Set Up the Model\n",
    "\n",
    "TODO: Explain why CSE and Adam are used and cite any research publications referenced (primarily from intuition from neural networks course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33310fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ff712",
   "metadata": {},
   "source": [
    "### Set Up Training Functionality\n",
    "\n",
    "The train_iter function trains the model for one epoch. The train_model function runs the train_iter function for the desired number of epochs in a loop.\n",
    "\n",
    "TODO: Explain how each part of the training function works, and possibly add some in-line comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6863703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iter(epoch, net, trainDataLoader, optimizer, criterion):\n",
    "    net.train()\n",
    "    total = 0\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for inputs, targets in trainDataLoader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    avg_loss = train_loss / len(trainDataLoader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Epoch: {} \\tTraining Loss: {:.25f} \\tTraining Accuracy: {:.4f} %'.format(epoch, avg_loss, accuracy))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51646581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_epochs, net, trainDataLoader, optimizer, criterion):\n",
    "  for i in range(num_epochs):\n",
    "    train_iter(i, net, trainDataLoader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c6eeb",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "Below, the model is trained for 150 epochs and interrupted by the keyboard once the loss was low and the training accuracy was high.\n",
    "\n",
    "TODO: Implement early stopping in the dataset by returning the avg_loss or accuracy at every iteration and breaking from the train_model loop if certain thresholds are met. Then, retrain and rerun the model to avoid using keyboard interrupts with error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b24939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining Loss: 5.3174726386373372122307046 \tTraining Accuracy: 55.6250 %\n",
      "Epoch: 1 \tTraining Loss: 3.8052916486581671584588094 \tTraining Accuracy: 56.7500 %\n",
      "Epoch: 2 \tTraining Loss: 3.0269927306758472873582377 \tTraining Accuracy: 55.5000 %\n",
      "Epoch: 3 \tTraining Loss: 1.6995186791010201687868175 \tTraining Accuracy: 57.7500 %\n",
      "Epoch: 4 \tTraining Loss: 1.0324230798892677363198800 \tTraining Accuracy: 60.8750 %\n",
      "Epoch: 5 \tTraining Loss: 0.9121752030495554608435782 \tTraining Accuracy: 63.5000 %\n",
      "Epoch: 6 \tTraining Loss: 0.7669148640334606525925665 \tTraining Accuracy: 67.7500 %\n",
      "Epoch: 7 \tTraining Loss: 0.7878732044436037584844712 \tTraining Accuracy: 65.8750 %\n",
      "Epoch: 8 \tTraining Loss: 0.7406022893218323632780198 \tTraining Accuracy: 69.1250 %\n",
      "Epoch: 9 \tTraining Loss: 0.8545966454222798658335591 \tTraining Accuracy: 60.5000 %\n",
      "Epoch: 10 \tTraining Loss: 0.7010076530091464697136416 \tTraining Accuracy: 69.5000 %\n",
      "Epoch: 11 \tTraining Loss: 0.6448295157030224933336626 \tTraining Accuracy: 70.5000 %\n",
      "Epoch: 12 \tTraining Loss: 0.6770897295605391441597476 \tTraining Accuracy: 69.6250 %\n",
      "Epoch: 13 \tTraining Loss: 0.7352215582132339832810430 \tTraining Accuracy: 68.3750 %\n",
      "Epoch: 14 \tTraining Loss: 0.6699590440653264700188174 \tTraining Accuracy: 70.5000 %\n",
      "Epoch: 15 \tTraining Loss: 0.6359976251702755822847735 \tTraining Accuracy: 71.0000 %\n",
      "Epoch: 16 \tTraining Loss: 0.6451993166096507970053153 \tTraining Accuracy: 69.8750 %\n",
      "Epoch: 17 \tTraining Loss: 0.6368147664237767680006641 \tTraining Accuracy: 72.2500 %\n",
      "Epoch: 18 \tTraining Loss: 0.6031743722036481125670093 \tTraining Accuracy: 74.2500 %\n",
      "Epoch: 19 \tTraining Loss: 0.6049535623937845052466855 \tTraining Accuracy: 73.8750 %\n",
      "Epoch: 20 \tTraining Loss: 0.6042968362569809404050147 \tTraining Accuracy: 72.8750 %\n",
      "Epoch: 21 \tTraining Loss: 0.5883281189389526488753290 \tTraining Accuracy: 72.5000 %\n",
      "Epoch: 22 \tTraining Loss: 0.6149718171590938808890314 \tTraining Accuracy: 73.3750 %\n",
      "Epoch: 23 \tTraining Loss: 0.6187432417739182621829741 \tTraining Accuracy: 72.5000 %\n",
      "Epoch: 24 \tTraining Loss: 0.5449488723091781006147016 \tTraining Accuracy: 76.5000 %\n",
      "Epoch: 25 \tTraining Loss: 0.5284469735994935524203697 \tTraining Accuracy: 76.8750 %\n",
      "Epoch: 26 \tTraining Loss: 0.5774774316744878399632057 \tTraining Accuracy: 75.5000 %\n",
      "Epoch: 27 \tTraining Loss: 0.6279583097714930284283241 \tTraining Accuracy: 73.0000 %\n",
      "Epoch: 28 \tTraining Loss: 0.5949774022446945309638977 \tTraining Accuracy: 76.2500 %\n",
      "Epoch: 29 \tTraining Loss: 0.5562329674861393735696424 \tTraining Accuracy: 76.8750 %\n",
      "Epoch: 30 \tTraining Loss: 0.5851534869661554338904352 \tTraining Accuracy: 76.3750 %\n",
      "Epoch: 31 \tTraining Loss: 0.5976061353948898258181543 \tTraining Accuracy: 75.8750 %\n",
      "Epoch: 32 \tTraining Loss: 0.4857797825243324041366577 \tTraining Accuracy: 78.6250 %\n",
      "Epoch: 33 \tTraining Loss: 0.5202396093169227020425183 \tTraining Accuracy: 76.0000 %\n",
      "Epoch: 34 \tTraining Loss: 0.6080797534063457909780936 \tTraining Accuracy: 78.2500 %\n",
      "Epoch: 35 \tTraining Loss: 0.5009977877233177112614726 \tTraining Accuracy: 80.5000 %\n",
      "Epoch: 36 \tTraining Loss: 0.5391108007496222542798137 \tTraining Accuracy: 78.7500 %\n",
      "Epoch: 37 \tTraining Loss: 0.5843190503586083162090858 \tTraining Accuracy: 76.2500 %\n",
      "Epoch: 38 \tTraining Loss: 0.5292057978035882292999759 \tTraining Accuracy: 77.1250 %\n",
      "Epoch: 39 \tTraining Loss: 0.5461992888164241000126253 \tTraining Accuracy: 77.8750 %\n",
      "Epoch: 40 \tTraining Loss: 0.5298023234226275635094794 \tTraining Accuracy: 79.7500 %\n",
      "Epoch: 41 \tTraining Loss: 0.4859968479280359909822096 \tTraining Accuracy: 80.5000 %\n",
      "Epoch: 42 \tTraining Loss: 0.4233274182287277698222283 \tTraining Accuracy: 83.6250 %\n",
      "Epoch: 43 \tTraining Loss: 0.4366495351093180876667077 \tTraining Accuracy: 81.3750 %\n",
      "Epoch: 44 \tTraining Loss: 0.4519788375613279507447828 \tTraining Accuracy: 83.3750 %\n",
      "Epoch: 45 \tTraining Loss: 0.3849880232976283789270155 \tTraining Accuracy: 84.0000 %\n",
      "Epoch: 46 \tTraining Loss: 0.4967441220814362012880849 \tTraining Accuracy: 80.1250 %\n",
      "Epoch: 47 \tTraining Loss: 0.4115229351801099055840893 \tTraining Accuracy: 84.2500 %\n",
      "Epoch: 48 \tTraining Loss: 0.5876713886228389638333169 \tTraining Accuracy: 79.8750 %\n",
      "Epoch: 49 \tTraining Loss: 0.3642626260695396855915362 \tTraining Accuracy: 83.5000 %\n",
      "Epoch: 50 \tTraining Loss: 0.3572276923921890445789984 \tTraining Accuracy: 84.8750 %\n",
      "Epoch: 51 \tTraining Loss: 0.4189058559213299504087047 \tTraining Accuracy: 86.2500 %\n",
      "Epoch: 52 \tTraining Loss: 0.3499091669451445119065625 \tTraining Accuracy: 87.5000 %\n",
      "Epoch: 53 \tTraining Loss: 0.3611653834942262775165034 \tTraining Accuracy: 85.7500 %\n",
      "Epoch: 54 \tTraining Loss: 0.3651102037308737724430330 \tTraining Accuracy: 85.3750 %\n",
      "Epoch: 55 \tTraining Loss: 0.2958411508874269069124807 \tTraining Accuracy: 89.3750 %\n",
      "Epoch: 56 \tTraining Loss: 0.2940305498320958665914304 \tTraining Accuracy: 88.3750 %\n",
      "Epoch: 57 \tTraining Loss: 0.3583415062183848975863043 \tTraining Accuracy: 87.0000 %\n",
      "Epoch: 58 \tTraining Loss: 0.3134708252240671066957134 \tTraining Accuracy: 88.3750 %\n",
      "Epoch: 59 \tTraining Loss: 0.2921176882188228907111238 \tTraining Accuracy: 88.5000 %\n",
      "Epoch: 60 \tTraining Loss: 0.2617793856986099787498290 \tTraining Accuracy: 89.0000 %\n",
      "Epoch: 61 \tTraining Loss: 0.3256726739832811468033924 \tTraining Accuracy: 87.0000 %\n",
      "Epoch: 62 \tTraining Loss: 0.2055021156438488205697723 \tTraining Accuracy: 91.8750 %\n",
      "Epoch: 63 \tTraining Loss: 0.3350036438726238241514466 \tTraining Accuracy: 87.7500 %\n",
      "Epoch: 64 \tTraining Loss: 0.2631133118202796938867039 \tTraining Accuracy: 89.1250 %\n",
      "Epoch: 65 \tTraining Loss: 0.3599130211523515754379332 \tTraining Accuracy: 87.3750 %\n",
      "Epoch: 66 \tTraining Loss: 0.2462268273052904965503274 \tTraining Accuracy: 90.2500 %\n",
      "Epoch: 67 \tTraining Loss: 0.2515058954842243066352125 \tTraining Accuracy: 91.5000 %\n",
      "Epoch: 68 \tTraining Loss: 0.2335499933008395589961737 \tTraining Accuracy: 92.1250 %\n",
      "Epoch: 69 \tTraining Loss: 0.2460493333855993114411831 \tTraining Accuracy: 91.2500 %\n",
      "Epoch: 70 \tTraining Loss: 0.1945321949897333979606628 \tTraining Accuracy: 94.0000 %\n",
      "Epoch: 71 \tTraining Loss: 0.2257556306911646937241045 \tTraining Accuracy: 92.8750 %\n",
      "Epoch: 72 \tTraining Loss: 0.2173444224932973289909910 \tTraining Accuracy: 92.1250 %\n",
      "Epoch: 73 \tTraining Loss: 0.2140990814439049927386804 \tTraining Accuracy: 93.3750 %\n",
      "Epoch: 74 \tTraining Loss: 0.1971376293951198066523034 \tTraining Accuracy: 93.2500 %\n",
      "Epoch: 75 \tTraining Loss: 0.1896454665524720528679836 \tTraining Accuracy: 93.0000 %\n",
      "Epoch: 76 \tTraining Loss: 0.2070236107507412159911553 \tTraining Accuracy: 92.6250 %\n",
      "Epoch: 77 \tTraining Loss: 0.1905610826858173956210862 \tTraining Accuracy: 93.5000 %\n",
      "Epoch: 78 \tTraining Loss: 0.1665147995647748846437253 \tTraining Accuracy: 93.3750 %\n",
      "Epoch: 79 \tTraining Loss: 0.1809925527201483030914630 \tTraining Accuracy: 93.3750 %\n",
      "Epoch: 80 \tTraining Loss: 0.2045957328155509347134000 \tTraining Accuracy: 93.1250 %\n",
      "Epoch: 81 \tTraining Loss: 0.1786504336649704649531145 \tTraining Accuracy: 93.0000 %\n",
      "Epoch: 82 \tTraining Loss: 0.1500959068240717841913323 \tTraining Accuracy: 94.6250 %\n",
      "Epoch: 83 \tTraining Loss: 0.1504739824638633705067292 \tTraining Accuracy: 94.3750 %\n",
      "Epoch: 84 \tTraining Loss: 0.1247597507611396816518123 \tTraining Accuracy: 95.3750 %\n",
      "Epoch: 85 \tTraining Loss: 0.1392735520963151452100703 \tTraining Accuracy: 94.8750 %\n",
      "Epoch: 86 \tTraining Loss: 0.1098725319015605300654315 \tTraining Accuracy: 96.1250 %\n",
      "Epoch: 87 \tTraining Loss: 0.1686803406457693110809259 \tTraining Accuracy: 94.5000 %\n",
      "Epoch: 88 \tTraining Loss: 0.2347119352743982367837106 \tTraining Accuracy: 92.1250 %\n",
      "Epoch: 89 \tTraining Loss: 0.0924663481525976743702344 \tTraining Accuracy: 96.1250 %\n",
      "Epoch: 90 \tTraining Loss: 0.1818964958241576779229831 \tTraining Accuracy: 93.8750 %\n",
      "Epoch: 91 \tTraining Loss: 0.1172545292531276400760376 \tTraining Accuracy: 96.3750 %\n",
      "Epoch: 92 \tTraining Loss: 0.1139215025017494969938880 \tTraining Accuracy: 96.0000 %\n",
      "Epoch: 93 \tTraining Loss: 0.1091267575425666769284305 \tTraining Accuracy: 95.3750 %\n",
      "Epoch: 94 \tTraining Loss: 0.1867219277171087432609653 \tTraining Accuracy: 94.0000 %\n",
      "Epoch: 95 \tTraining Loss: 0.1584898382745268397009397 \tTraining Accuracy: 94.6250 %\n",
      "Epoch: 96 \tTraining Loss: 0.1359085176779217252196474 \tTraining Accuracy: 95.0000 %\n",
      "Epoch: 97 \tTraining Loss: 0.1362193231999395959253008 \tTraining Accuracy: 95.1250 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98 \tTraining Loss: 0.0879046634193468845452912 \tTraining Accuracy: 96.6250 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n3/dl05lzw17xb4p_j9_8b9p0w80000gn/T/ipykernel_31067/1308636096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n3/dl05lzw17xb4p_j9_8b9p0w80000gn/T/ipykernel_31067/587993460.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs, net, trainDataLoader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/n3/dl05lzw17xb4p_j9_8b9p0w80000gn/T/ipykernel_31067/3510338930.py\u001b[0m in \u001b[0;36mtrain_iter\u001b[0;34m(epoch, net, trainDataLoader, optimizer, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainDataLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n3/dl05lzw17xb4p_j9_8b9p0w80000gn/T/ipykernel_31067/1388641816.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n3/dl05lzw17xb4p_j9_8b9p0w80000gn/T/ipykernel_31067/1388641816.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mCNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 443\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(150, model, train, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b67f92",
   "metadata": {},
   "source": [
    "### Evaluate the Model on the Test Set\n",
    "\n",
    "TODO: Be consistent with the test/validation terminology used throughout this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e6c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(net, testDataLoader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testDataLoader:\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += len(targets)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "    print('Accuracy of the network on the set of %d test images: %d %%' % (total,\n",
    "        100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f91106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the set of 200 test images: 69 %\n"
     ]
    }
   ],
   "source": [
    "eval_model(model, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
